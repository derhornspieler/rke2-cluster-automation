# Optional override for the namespace where chart resources are created.
# Leave empty to use the Helm release namespace passed via `-n/--namespace`.
namespaceOverride: ""

# ------------------------------------------------------------------
# Global settings
# ------------------------------------------------------------------
replicaCounts:
  controlPlane: 3          # number of RKE2 control‑plane VMs
  worker: 1            # number of RKE2 worker VMs

resources:
  controlPlane:
    cpuCores: 4                 # initial CPU sockets/cores
    maxCpuSockets: 2            # optional ceiling for CPU hotplug (defaults to cpuCores)
    memoryMi: 16386             # initial guest memory in MiB
    maxMemoryMi: 16386          # optional ceiling for memory hotplug (defaults to memoryMi)
    enableHotplug: false        # add harvesterhci.io/enableCPUAndMemoryHotplug
  worker:
    cpuCores: 4
    maxCpuSockets: 2
    memoryMi: 16386
    maxMemoryMi: 16386
    enableHotplug: false

image:
  namespace: harvester-public        # Namespace that holds the VirtualMachineImage
  name: rocky-9-cloudimg             # Must exist in Harvester’s image catalog
  pullPolicy: IfNotPresent

vmNamePrefix: rke2                   # Prefix for generated VM names (defaults to Helm release name)

controlPlane:
  allowWorkloads: true               # If false, taint control planes with NoSchedule to keep user workloads off them

storage:
  className: ""                     # leave empty to use Harvester's per-image storage class
  accessMode: ReadWriteMany
  volumeMode: Block
  size: 30Gi
  controlPlaneSize: 100Gi
  workerSize: 150Gi

networks:
  vm:
    namespace: hvst-mgmt
    name: vlan2003                   # Workload VM network (VLAN 2003)
    interface: eth0                  # Guest interface name used in networkData
    prefix: 24                       # CIDR prefix length for static IPs
    gateway: ""                      # Optional gateway inserted into networkData
    nameservers: []                  # Optional DNS servers for static IPs
    dhcp:
      controlPlane: false
      worker: false
    macAddresses:
      controlPlane: []               # Optional list of MACs per control-plane VM
      worker: []                     # Optional list of MACs per worker VM
    staticIPs:
      controlPlane: []               # Optional static IPv4 list per control-plane VM
      worker: []                     # Optional static IPv4 list per worker VM
  rancher:
    enabled: false                  # Set true to attach a second interface dedicated to Rancher
    namespace: ""                  # Namespace of the Rancher NetworkAttachmentDefinition
    name: ""                       # Name of the Rancher NetworkAttachmentDefinition
    interface: eth1                 # Guest interface name for the secondary NIC
    prefix: 24                      # CIDR prefix for static IPs on the Rancher NIC
    routes: []                      # Optional list of extra routes (to/24 via/scope) for the Rancher NIC
    staticIPs:
      controlPlane: []              # Static IPv4s for control-plane VMs on the Rancher NIC
      worker: []                    # Static IPv4s for worker VMs on the Rancher NIC

# Legacy Harvester LoadBalancer values (unused when kubeVip.enabled=true)
loadBalancer:
  enabled: false
  namespace: default
  vip: ""
  subnet: ""
  gateway: ""
  network: ""

kubeVip:
  enabled: false
  namespace: kube-system
  useDaemonSet: true
  vip_address: ""                    # VIP address
  vip_interface: eth0                # Interface for the VIP
  vip_cidr: ""                       # CIDR for the VIP (e.g. 172.16.3.1/24 or just 24)
  imageRepository: ghcr.io/kube-vip/kube-vip
  imageTag: v0.8.9
  imagePullPolicy: IfNotPresent
  imagePullSecrets: []
  ttl: 30
  arp: true
  leaderElection: true
  cpEnabled: true
  svc_enabled: false
  lb_enabled: false
  serviceAccountName: kube-vip-static       # ServiceAccount used by the static pod
  rbac:
    create: true                     # Set false if you manage kube-vip RBAC yourself
  securityContext:
    capabilities:
      add:
        - NET_ADMIN
        - NET_RAW
        - SYS_TIME
  hostNetwork: true                  # Set false if you manage kube-vip RBAC yourself

tlsSANs:
  - internal-vip.local

ssh:
  user: rocky                     # user that cloud‑init will create
  publicKey: "ssh-ed25519 "  # fill with your SSH public key (optional)

rke2:
  token: ""  # will be filled from secret rke2-token
  version: "v1.33.5+rke2r1"        # RKE2 version you want to run
  cni: "canal"                     # or calico, multus, etc.

rancherManager:
  enabled: false
  chartRepo: https://releases.rancher.com/server-charts/latest
  chartName: rancher
  chartVersion: ""
  helmChartNamespace: kube-system
  namespace: cattle-system
  hostname: ""
  bootstrapPassword: ""
  replicas: 3
  rancherManager:
    extraEnv:
      - name: CATTLE_SERVER_URL
        value: https://rancher.yourdomain.com
  service:
    type: LoadBalancer
    loadBalancerIP: ""
    annotations: {}
  ingress:
    tlsSource: secret           # rancher (default self-signed), letsEncrypt, or secret/private-ca
    tlsSecretName: ""          # Required when tlsSource=secret
    tlsSecret:                 # Optional inline TLS secret material (PEM); requires tlsSource=secret
      create: false
      certificate: ""          # Include PEM content, e.g. -----BEGIN CERTIFICATE-----
      privateKey: ""           # Include PEM content, e.g. -----BEGIN PRIVATE KEY-----
    extraAnnotations: {}

metallb:
  enabled: false
  chartRepo: https://metallb.github.io/metallb
  chartName: metallb
  chartVersion: ""
  helmChartNamespace: kube-system
  namespace: metallb-system
  valuesContent: ""
  values: {}
  addressPools: []              # e.g. [{ name: rancher, protocol: layer2, autoAssign: false, addresses: ["192.168.10.6-192.168.10.9"] }]
    # - name: rancher-vip
    #   protocol: layer2
    #   autoAssign: false
    #   addresses:
    #     - 172.16.3.6-172.16.3.6   # dedicated IP for Rancher
certManager:
  enabled: false
  chartRepo: https://charts.jetstack.io
  chartName: cert-manager
  chartVersion: ""
  helmChartNamespace: kube-system
  namespace: cert-manager
  installCRDs: true
  valuesContent: ""
  values: {}
  certificate:
    create: false
    secretName: ""
    commonName: ""
    dnsNames: []
    issuerRef:
      name: ""
      kind: ClusterIssuer
      group: cert-manager.io
  ca:
    create: false
    secretName: ""
    commonName: ""
    issuerName: ""
    selfSignedIssuerName: ""
    certificateName: ""

cloudProvider:
  cloudConfig: ""              # Inline kubeconfig for Harvester CCM (optional)
  # cloudConfig: |
    # ########## cloud config ############
    # apiVersion: v1
    # clusters:
    # - cluster:
    #     insecure-skip-tls-verify: true
    #     server: https://172.16.2.2/k8s/clusters/local
    #   name: local
    # contexts:
    # - context:
    #     cluster: local
    #     namespace: rke2
    #     user: rke2-mgmt-cloud-provider-rke2-local
    #   name: rke2-mgmt-cloud-provider-rke2-local
    # current-context: rke2-mgmt-cloud-provider-rke2-local
    # kind: Config
    # users:
    # - name: rke2-mgmt-cloud-provider-rke2-local
    #   user:
    #     token: <token>
  configPath: /var/lib/rancher/rke2/etc/config-files/cloud-provider-config

vmDeployment:
  image: alpine/kubectl:1.34.2
  backoffLimit: 3

harvesterTemplates:
  enabled: true
